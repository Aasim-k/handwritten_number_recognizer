{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec88818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74fad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    # transforms.RandomApply([transforms.CenterCrop(22), ], p=0.1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.RandomRotation((-15., 15.), fill=0),\n",
    "    # transforms.CenterCrop(18),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.13252,), (0.31048,))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2ff820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795bead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4aa2f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_data, batch_label = next(iter(train_dataloader))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(12):\n",
    "  plt.subplot(3,4,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
    "  plt.title(batch_label[i].item())\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92832325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1fb865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistFullyCNN(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.05, inplace=False)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.05, inplace=False)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.05, inplace=False)\n",
      "    (4): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(16, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MnistFullyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # First block\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),  # 28x28 -> 28x28\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            # nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1), # 28x28 -> 28x28\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.MaxPool2d(2, 2)  # 28x28 -> 14x14\n",
    "        )\n",
    "        \n",
    "        # Second block\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1), # 14x14 -> 14x14\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            # nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), # 14x14 -> 14x14\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.MaxPool2d(2, 2)  # 14x14 -> 7x7\n",
    "        )\n",
    "        \n",
    "        # Third block\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1), # 7x7 -> 7x7\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Conv2d(32, 16, kernel_size=1, stride=1)  # 1x1 conv for dimension reduction\n",
    "        )\n",
    "        \n",
    "        # Final classification layer - fully convolutional\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 10, kernel_size=1, stride=1),  # 1x1 conv for 10 classes\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 10)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = MnistFullyCNN()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456ce3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17941b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 16, 14, 14]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 8, 28, 28]           80\n",
      "|    └─ReLU: 2-2                         [-1, 8, 28, 28]           --\n",
      "|    └─BatchNorm2d: 2-3                  [-1, 8, 28, 28]           16\n",
      "|    └─Conv2d: 2-4                       [-1, 16, 28, 28]          1,168\n",
      "|    └─ReLU: 2-5                         [-1, 16, 28, 28]          --\n",
      "|    └─BatchNorm2d: 2-6                  [-1, 16, 28, 28]          32\n",
      "|    └─Dropout: 2-7                      [-1, 16, 28, 28]          --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 16, 14, 14]          --\n",
      "├─Sequential: 1-2                        [-1, 32, 7, 7]            --\n",
      "|    └─Conv2d: 2-9                       [-1, 16, 14, 14]          2,320\n",
      "|    └─ReLU: 2-10                        [-1, 16, 14, 14]          --\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 16, 14, 14]          32\n",
      "|    └─Conv2d: 2-12                      [-1, 32, 14, 14]          4,640\n",
      "|    └─ReLU: 2-13                        [-1, 32, 14, 14]          --\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 32, 14, 14]          64\n",
      "|    └─Dropout: 2-15                     [-1, 32, 14, 14]          --\n",
      "|    └─MaxPool2d: 2-16                   [-1, 32, 7, 7]            --\n",
      "├─Sequential: 1-3                        [-1, 16, 7, 7]            --\n",
      "|    └─Conv2d: 2-17                      [-1, 32, 7, 7]            9,248\n",
      "|    └─ReLU: 2-18                        [-1, 32, 7, 7]            --\n",
      "|    └─BatchNorm2d: 2-19                 [-1, 32, 7, 7]            64\n",
      "|    └─Dropout: 2-20                     [-1, 32, 7, 7]            --\n",
      "|    └─Conv2d: 2-21                      [-1, 16, 7, 7]            528\n",
      "├─Sequential: 1-4                        [-1, 10, 1, 1]            --\n",
      "|    └─Conv2d: 2-22                      [-1, 10, 7, 7]            170\n",
      "|    └─AdaptiveAvgPool2d: 2-23           [-1, 10, 1, 1]            --\n",
      "==========================================================================================\n",
      "Total params: 18,362\n",
      "Trainable params: 18,362\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 2.82\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.46\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 0.54\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 16, 14, 14]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 8, 28, 28]           80\n",
       "|    └─ReLU: 2-2                         [-1, 8, 28, 28]           --\n",
       "|    └─BatchNorm2d: 2-3                  [-1, 8, 28, 28]           16\n",
       "|    └─Conv2d: 2-4                       [-1, 16, 28, 28]          1,168\n",
       "|    └─ReLU: 2-5                         [-1, 16, 28, 28]          --\n",
       "|    └─BatchNorm2d: 2-6                  [-1, 16, 28, 28]          32\n",
       "|    └─Dropout: 2-7                      [-1, 16, 28, 28]          --\n",
       "|    └─MaxPool2d: 2-8                    [-1, 16, 14, 14]          --\n",
       "├─Sequential: 1-2                        [-1, 32, 7, 7]            --\n",
       "|    └─Conv2d: 2-9                       [-1, 16, 14, 14]          2,320\n",
       "|    └─ReLU: 2-10                        [-1, 16, 14, 14]          --\n",
       "|    └─BatchNorm2d: 2-11                 [-1, 16, 14, 14]          32\n",
       "|    └─Conv2d: 2-12                      [-1, 32, 14, 14]          4,640\n",
       "|    └─ReLU: 2-13                        [-1, 32, 14, 14]          --\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 32, 14, 14]          64\n",
       "|    └─Dropout: 2-15                     [-1, 32, 14, 14]          --\n",
       "|    └─MaxPool2d: 2-16                   [-1, 32, 7, 7]            --\n",
       "├─Sequential: 1-3                        [-1, 16, 7, 7]            --\n",
       "|    └─Conv2d: 2-17                      [-1, 32, 7, 7]            9,248\n",
       "|    └─ReLU: 2-18                        [-1, 32, 7, 7]            --\n",
       "|    └─BatchNorm2d: 2-19                 [-1, 32, 7, 7]            64\n",
       "|    └─Dropout: 2-20                     [-1, 32, 7, 7]            --\n",
       "|    └─Conv2d: 2-21                      [-1, 16, 7, 7]            528\n",
       "├─Sequential: 1-4                        [-1, 10, 1, 1]            --\n",
       "|    └─Conv2d: 2-22                      [-1, 10, 7, 7]            170\n",
       "|    └─AdaptiveAvgPool2d: 2-23           [-1, 10, 1, 1]            --\n",
       "==========================================================================================\n",
       "Total params: 18,362\n",
       "Trainable params: 18,362\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.82\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.46\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 0.54\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (1, 28, 28), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2ee64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b34d7b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (image, label) in enumerate(dataloader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e90b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataloader:\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            pred = model(image)\n",
    "            test_loss += loss_fn(pred, label).item()\n",
    "            correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba27dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.336726  [   64/60000]\n",
      "loss: 1.689698  [ 3264/60000]\n",
      "loss: 0.887439  [ 6464/60000]\n",
      "loss: 0.490381  [ 9664/60000]\n",
      "loss: 0.302961  [12864/60000]\n",
      "loss: 0.302640  [16064/60000]\n",
      "loss: 0.332581  [19264/60000]\n",
      "loss: 0.316587  [22464/60000]\n",
      "loss: 0.225675  [25664/60000]\n",
      "loss: 0.099227  [28864/60000]\n",
      "loss: 0.275711  [32064/60000]\n",
      "loss: 0.237806  [35264/60000]\n",
      "loss: 0.229908  [38464/60000]\n",
      "loss: 0.109807  [41664/60000]\n",
      "loss: 0.237496  [44864/60000]\n",
      "loss: 0.205639  [48064/60000]\n",
      "loss: 0.168310  [51264/60000]\n",
      "loss: 0.077375  [54464/60000]\n",
      "loss: 0.062080  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.086472 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.212797  [   64/60000]\n",
      "loss: 0.101853  [ 3264/60000]\n",
      "loss: 0.153440  [ 6464/60000]\n",
      "loss: 0.080272  [ 9664/60000]\n",
      "loss: 0.179666  [12864/60000]\n",
      "loss: 0.075788  [16064/60000]\n",
      "loss: 0.169703  [19264/60000]\n",
      "loss: 0.096691  [22464/60000]\n",
      "loss: 0.101705  [25664/60000]\n",
      "loss: 0.246241  [28864/60000]\n",
      "loss: 0.161908  [32064/60000]\n",
      "loss: 0.122833  [35264/60000]\n",
      "loss: 0.036263  [38464/60000]\n",
      "loss: 0.017967  [41664/60000]\n",
      "loss: 0.020395  [44864/60000]\n",
      "loss: 0.014942  [48064/60000]\n",
      "loss: 0.098519  [51264/60000]\n",
      "loss: 0.053511  [54464/60000]\n",
      "loss: 0.021445  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.064328 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.085309  [   64/60000]\n",
      "loss: 0.165705  [ 3264/60000]\n",
      "loss: 0.106052  [ 6464/60000]\n",
      "loss: 0.012558  [ 9664/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 13\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/dissertation/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/dissertation/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniforge3/envs/dissertation/lib/python3.10/site-packages/torch/optim/adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    235\u001b[0m         group,\n\u001b[1;32m    236\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         state_steps,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/dissertation/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/dissertation/lib/python3.10/site-packages/torch/optim/adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/dissertation/lib/python3.10/site-packages/torch/optim/adam.py:425\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    423\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m device_beta1)\n\u001b[0;32m--> 425\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    428\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06441ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
